## data leakage
- モデルを作るときに,　本来知らないはずの情報を使ってしまうこと
- 訓練では高い精度が出るが,　テストでは精度がでない現状に陥る.
  - データリークにより,　モデルを作成して評価するまでは,　とても性能の良いモデルに見えてしまう.

## 2種類のデータリーク (target leakage, train-test contamination)

**target leakage**

予測をする際に利用するべきでないデータを使用して予測をしようとした際に発生する.
予測の時点では利用できない​情報を含むデータセットに基づいて​アルゴリズム​​をトレーニングし,　そのモデルを将来収集するデータに適用する場合に発生.


| got_pneumonia |  age  | weight | male  | took_antibiotic_medicine |
| :-----------: | :---: | :----: | :---: | :----------------------: |
|     False     |  65   |  100   | False |          False           |
|     False     |  72   |  130   | True  |          False           |
|     True      |  58   |  100   | False |           True           |

took_antibiotic_medicineの値がfalseの人は肺炎になっていないということである.　このモデルは現実世界に当てはめると不適切なモデルである.　将来肺炎になる人であっても,　また構成物質を投与されていなこともある（モデルを使って予測を行った時に）

## target leakageを回避する方法

ターゲットの成果の時点で不明なデータを除外する.　医療現場で患者がある病気を患っているかどうかを予測するためのモデルを作成するとする.　モデルを構築する際,　診断する前までに発生するデータ(外来データ,　検査データなど)のみでモデルを構築する必要がある.　診断後に発生するデータを含めてはいけない.　診断後のデータはモデルを適用して予測する時点では不明なデータであるからである.

**train-test contamination**

訓練データと検証データをしっかりと区別するように注意していない場合に起こりうる.

